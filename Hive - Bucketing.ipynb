{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001fd281",
   "metadata": {},
   "source": [
    "# Hive - Bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.'Hive Bucketing' - is a technique to split the data into more manageable files, (By specifying the number of buckets to create). The value of the bucketing column will be hashed by a user-defined number into buckets.\n",
    "\n",
    "2.Bucketing can be created on just 'one column', you can also create bucketing on a partitioned table to further split \n",
    "  the data to improve the query performance of the partitioned table.\n",
    "\n",
    "3.Each bucket is stored as a file within the table’s directory or the partitions directories on HDFS.\n",
    "\n",
    "4.Records with the same value in a column will always be stored in the same bucket.\n",
    "\n",
    "5.Hive bucketing commonly created in two scenarios.\n",
    "  i. Create a bucket on top of the Partitioned table to further divide the table for better query performance.\n",
    "  ii.Create Bucketing on the table where you cannot choose the partition column due to (too many distinct values on columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bbe012",
   "metadata": {},
   "source": [
    "# Hive Create Bucketing Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674fa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE zipcodes(\n",
    "RecordNumber int,\n",
    "Country string,\n",
    "City string,\n",
    "Zipcode int)\n",
    "PARTITIONED BY(state string)\n",
    "CLUSTERED BY (Zipcode) INTO 32 BUCKETS #syntax for bucketing Creation\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ',';\n",
    "\n",
    "#Load Data into Bucket\n",
    "\n",
    "#This property is not needed if you are using Hive 2.x or later\n",
    "set hive.enforce.bucketing = true;\n",
    "\n",
    "LOAD DATA INPATH '/data/zipcodes.csv' INTO TABLE zipcodes;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c44678",
   "metadata": {},
   "source": [
    "# Select Data From Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "Since our zipcode is partitioned on state and bucketing on zipcode, if you use these columns on where condition your query \n",
    "returns faster results.\n",
    "\n",
    "'SELECT * FROM zipcodes WHERE state='PR' and zipcode=704;'\n",
    "+------------------------+-------------------+----------------------+-------------------+-----------------+s\n",
    "| zipcodes.recordnumber  | zipcodes.country  |    zipcodes.city     | zipcodes.zipcode  | zipcodes.state  |\n",
    "+------------------------+-------------------+----------------------+-------------------+-----------------+\n",
    "| 3                      | US                | SECT LANAUSSE        | 704               | PR              |\n",
    "| 2                      | US                | PASEO COSTA DEL SUR  | 704               | PR              |\n",
    "| 4                      | US                | URB EUGENE RICE      | 704               | PR              |\n",
    "| 1                      | US                | PARC PARQUE          | 704               | PR              |\n",
    "+------------------------+-------------------+----------------------+-------------------+-----------------+\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7baca4c",
   "metadata": {},
   "source": [
    "# How Hive Distribute the Rows Across the Buckets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9acd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "In general, the bucket number is determined by the expression 'hash_function(bucketing_column) mod num_buckets'\n",
    "\n",
    "Example --\n",
    "if user_id were an int, and there were 10 buckets, we would expect all user_id’s that end in 0 to be in bucket 1, \n",
    "all user_id’s that end in a 1 to be in bucket 2,\n",
    "all user_id’s that end in a 2 to be in bucket 3, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0908a7",
   "metadata": {},
   "source": [
    "# How to Decide the Number of Buckets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37fd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lets take a scenario Where table size is: 2300 MB, HDFS Block Size: 128 MB\n",
    "\n",
    "Now, Divide 2300/128=17.96\n",
    "\n",
    "Now, remember number of bucket will always be in the power of 2.\n",
    "\n",
    "So we need to find n such that 2^n > 17.96\n",
    "\n",
    "n=5\n",
    "\n",
    "So, I am going to use number of buckets as 2^5=32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8a87c",
   "metadata": {},
   "source": [
    "# Differences Between Hive Partitioning vs Bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7739575",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PARTITIONING                                        \tBUCKETING'\n",
    "\n",
    "Directory is created on HDFS for each partition.    \tFile is created on HDFS for each bucket.\n",
    "You can have one or more Partition columns          \tYou can have only one Bucketing column\n",
    "You can’t manage the number of partitions to create  \tYou can manage the number of buckets to create by specifying the count\n",
    "NA                                                   \tBucketing can be created on a partitioned table\n",
    "Uses PARTITIONED BY                                 \tUses CLUSTERED BY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
